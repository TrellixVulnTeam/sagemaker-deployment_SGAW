{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U pandas pandas-profiling scikit-learn sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  52.0  1.0  1.0     118.0  186.0  0.0      2.0    190.0    0.0      0.0   \n",
       "1  39.0  0.0  3.0      94.0  199.0  0.0      0.0    179.0    0.0      0.0   \n",
       "2  60.0  1.0  4.0     130.0  206.0  0.0      2.0    132.0    1.0      2.4   \n",
       "3  39.0  1.0  3.0     140.0  321.0  0.0      2.0    182.0    0.0      0.0   \n",
       "4  57.0  0.0  4.0     120.0  354.0  0.0      0.0    163.0    1.0      0.6   \n",
       "\n",
       "   slope   ca  thal  target  \n",
       "0    2.0  0.0   6.0       0  \n",
       "1    1.0  0.0   3.0       0  \n",
       "2    2.0  2.0   7.0       1  \n",
       "3    1.0  0.0   3.0       0  \n",
       "4    1.0  0.0   3.0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/train.csv\", \n",
    "    nrows=100\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/test.csv\")\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d783ae815a84562aa9fb964f5b59415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b704afabc74d268f5c99d3643fd5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c14bb9e194ec8a4d3ccd49a2c65ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99b69e1a4084786a9baaf30bca9642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(train_df)\n",
    "profile.to_file('profile_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Features and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns\n",
    "cat_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "cont_cols = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X(features) and y(response)\n",
    "X_train = train_df.drop(\"target\", axis=1)\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the categorical columns\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "# Scale the continuous columns\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Column transformer to apply transformations on both categorical and continuous columns\n",
    "ct = ColumnTransformer([\n",
    "    (\"One Hot Encoding\", ohe, cat_cols),\n",
    "    (\"Scaling\", sc, cont_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model\n",
    "- Random Forest documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to combine feature engineering and ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rfc_model = Pipeline([\n",
    "    (\"Data Transformations\", ct),\n",
    "    (\"Random Forest Model\", rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Pipeline Model locally\n",
    "- We run it locally to ensure there are no bugs in the code!\n",
    "- For this \"test\" purpose we can just run it on a smaller subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view tha Pipeline model as a diagram\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac {color: black;background-color: white;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac pre{padding: 0;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-toggleable {background-color: white;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-estimator:hover {background-color: #d4ebff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-item {z-index: 1;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-parallel-item:only-child::after {width: 0;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-2275f3ee-3b8e-4b15-8b04-e70ae0838cac\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Data Transformations&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;One Hot Encoding&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;cp&#x27;, &#x27;fbs&#x27;,\n",
       "                                                   &#x27;restecg&#x27;, &#x27;exang&#x27;, &#x27;slope&#x27;,\n",
       "                                                   &#x27;ca&#x27;, &#x27;thal&#x27;]),\n",
       "                                                 (&#x27;Scaling&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;])])),\n",
       "                (&#x27;Random Forest Model&#x27;, RandomForestClassifier())])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0f09b97c-401f-4944-9441-c2e71755a22a\" type=\"checkbox\" ><label for=\"0f09b97c-401f-4944-9441-c2e71755a22a\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Data Transformations&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;One Hot Encoding&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                                  [&#x27;sex&#x27;, &#x27;cp&#x27;, &#x27;fbs&#x27;,\n",
       "                                                   &#x27;restecg&#x27;, &#x27;exang&#x27;, &#x27;slope&#x27;,\n",
       "                                                   &#x27;ca&#x27;, &#x27;thal&#x27;]),\n",
       "                                                 (&#x27;Scaling&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;,\n",
       "                                                   &#x27;thalach&#x27;, &#x27;oldpeak&#x27;])])),\n",
       "                (&#x27;Random Forest Model&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4b9dd7fd-9af9-4cc3-b928-d4e95e514bc6\" type=\"checkbox\" ><label for=\"4b9dd7fd-9af9-4cc3-b928-d4e95e514bc6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Data Transformations: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;One Hot Encoding&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 [&#x27;sex&#x27;, &#x27;cp&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;exang&#x27;,\n",
       "                                  &#x27;slope&#x27;, &#x27;ca&#x27;, &#x27;thal&#x27;]),\n",
       "                                (&#x27;Scaling&#x27;, StandardScaler(),\n",
       "                                 [&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;,\n",
       "                                  &#x27;oldpeak&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4793e06b-afbb-4f3d-9156-08e7ecf3c741\" type=\"checkbox\" ><label for=\"4793e06b-afbb-4f3d-9156-08e7ecf3c741\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">One Hot Encoding</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex&#x27;, &#x27;cp&#x27;, &#x27;fbs&#x27;, &#x27;restecg&#x27;, &#x27;exang&#x27;, &#x27;slope&#x27;, &#x27;ca&#x27;, &#x27;thal&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1221f5f2-03ba-4824-b3e0-1ed2334d8782\" type=\"checkbox\" ><label for=\"1221f5f2-03ba-4824-b3e0-1ed2334d8782\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7b07faa6-9052-41e3-be1e-d82190475479\" type=\"checkbox\" ><label for=\"7b07faa6-9052-41e3-be1e-d82190475479\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaling</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;, &#x27;trestbps&#x27;, &#x27;chol&#x27;, &#x27;thalach&#x27;, &#x27;oldpeak&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e28f0e64-b0d6-4b53-9915-d13607c07b17\" type=\"checkbox\" ><label for=\"e28f0e64-b0d6-4b53-9915-d13607c07b17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a88dacfb-c06d-410c-bb87-6a5d8d104483\" type=\"checkbox\" ><label for=\"a88dacfb-c06d-410c-bb87-6a5d8d104483\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Data Transformations',\n",
       "                 ColumnTransformer(transformers=[('One Hot Encoding',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['sex', 'cp', 'fbs',\n",
       "                                                   'restecg', 'exang', 'slope',\n",
       "                                                   'ca', 'thal']),\n",
       "                                                 ('Scaling', StandardScaler(),\n",
       "                                                  ['age', 'trestbps', 'chol',\n",
       "                                                   'thalach', 'oldpeak'])])),\n",
       "                ('Random Forest Model', RandomForestClassifier())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model locally on a smaller subset of data\n",
    "pipeline_rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy on training data\n",
    "train_accuracy = pipeline_rfc_model.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Check the accuracy on test data\n",
    "test_accuracy = pipeline_rfc_model.score(X_test, y_test)\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Pipeline Model on Sagemaker!\n",
    "- Since the model is free from bugs, we can train it on the full dataset.\n",
    "- Sagemaker training allows us to scale training to large datasets.\n",
    "- First we need to put all the code into a .py script\n",
    "- Sagemaker API documentation: https://sagemaker.readthedocs.io/en/stable/api/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_file_name = \"pipeline_model.joblib\"\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Inbuilt Arguments: https://github.com/aws/sagemaker-containers#id11\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    \n",
    "    # Custom Arguments\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--min_samples_split\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--criterion\", type=str, default=\"gini\")\n",
    "    \n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/train.csv\")\n",
    "    test_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/test.csv\")\n",
    "\n",
    "    # Define the columns\n",
    "    cat_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "    cont_cols = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "\n",
    "    # Split X(features) and y(response)\n",
    "    X_train = train_df.drop(\"target\", axis=1)\n",
    "    y_train = train_df[\"target\"]\n",
    "\n",
    "    X_test = test_df.drop(\"target\", axis=1)\n",
    "    y_test = test_df[\"target\"]\n",
    "\n",
    "    # One hot encode the categorical columns\n",
    "    ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "    # Scale the continuous columns\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Column transformer to apply transformations on both categorical and continuous columns\n",
    "    ct = ColumnTransformer([\n",
    "        (\"One Hot Encoding\", ohe, cat_cols),\n",
    "        (\"Scaling\", sc, cont_cols)\n",
    "    ])\n",
    "    \n",
    "    # Random Forest Model\n",
    "    rfc = RandomForestClassifier(n_estimators=args.n_estimators, \n",
    "                                 min_samples_split=args.min_samples_split, \n",
    "                                 criterion=args.criterion)\n",
    "\n",
    "    # Sklearn pipeline\n",
    "    pipeline_rfc_model = Pipeline([\n",
    "        (\"Data Transformations\", ct),\n",
    "        (\"Random Forest Model\", rfc)\n",
    "    ])\n",
    "\n",
    "    # Fit the model locally on a smaller subset of data\n",
    "    pipeline_rfc_model.fit(X_train, y_train)\n",
    "\n",
    "    # Check the accuracy on training data\n",
    "    train_accuracy = pipeline_rfc_model.score(X_train, y_train)\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Check the accuracy on test data\n",
    "    test_accuracy = pipeline_rfc_model.score(X_test, y_test)\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = os.path.join(args.model_dir, model_file_name)\n",
    "    joblib.dump(pipeline_rfc_model, model_save_path)\n",
    "    print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "# Run the main function when the script runs\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "scikit-learn\n",
    "fsspec\n",
    "s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-25 12:17:45 Starting - Starting the training job...\n",
      "2022-06-25 12:17:47 Starting - Launching requested ML instancesProfilerReport-1656159465: InProgress\n",
      ".........\n",
      "2022-06-25 12:19:28 Starting - Preparing the instances for training............\n",
      "2022-06-25 12:21:45 Downloading - Downloading input data\n",
      "2022-06-25 12:21:45 Training - Training image download completed. Training in progress..\u001b[34m2022-06-25 12:21:45,968 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:45,971 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:45,979 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:46,294 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /miniconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.0.2)\u001b[0m\n",
      "\u001b[34mCollecting fsspec\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 kB 10.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting s3fs\n",
      "  Downloading s3fs-2022.5.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2022.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /miniconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (1.21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /miniconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp<=4\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 59.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore~=2.3.0\n",
      "  Downloading aiobotocore-2.3.3.tar.gz (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.7/65.7 kB 5.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.24.22,>=1.24.21\n",
      "  Downloading botocore-1.24.21-py3-none-any.whl (8.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 108.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wrapt>=1.10.10\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 7.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.10.0-py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mCollecting attrs>=17.3.0\n",
      "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 13.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 11.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 32.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /miniconda3/lib/python3.8/site-packages (from aiohttp<=4->s3fs->-r requirements.txt (line 4)) (2.0.4)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 35.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting typing_extensions>=4.0\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /miniconda3/lib/python3.8/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs->-r requirements.txt (line 4)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /miniconda3/lib/python3.8/site-packages (from botocore<1.24.22,>=1.24.21->aiobotocore~=2.3.0->s3fs->-r requirements.txt (line 4)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /miniconda3/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp<=4->s3fs->-r requirements.txt (line 4)) (3.3)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: aiobotocore\n",
      "  Building wheel for aiobotocore (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-2.3.3-py3-none-any.whl size=64640 sha256=29341fff86080857f9d0b32c2f57957399277d104ac77e7c2e3ef0cf29e210b8\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/6e/0f/42f612c80c69b908c85aa37405b56c90ad1e59dc8e0e9415a0\u001b[0m\n",
      "\u001b[34mSuccessfully built aiobotocore\u001b[0m\n",
      "\u001b[34mInstalling collected packages: wrapt, typing_extensions, multidict, fsspec, frozenlist, attrs, async-timeout, yarl, botocore, aiosignal, aioitertools, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.19.4\n",
      "    Uninstalling botocore-1.19.4:\n",
      "      Successfully uninstalled botocore-1.19.4\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34msagemaker-sklearn-container 2.0 requires botocore==1.19.4, but you have botocore 1.24.21 which is incompatible.\u001b[0m\n",
      "\u001b[34mboto3 1.16.4 requires botocore<1.20.0,>=1.19.4, but you have botocore 1.24.21 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiobotocore-2.3.3 aiohttp-3.8.1 aioitertools-0.10.0 aiosignal-1.2.0 async-timeout-4.0.2 attrs-21.4.0 botocore-1.24.21 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 s3fs-2022.5.0 typing_extensions-4.2.0 wrapt-1.14.1 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:54,440 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:54,452 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:54,462 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-25 12:21:54,471 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"criterion\": \"gini\",\n",
      "        \"min_samples_split\": 0.05,\n",
      "        \"n_estimators\": 50\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rfc-pipeline-run-2022-06-25-12-17-45-068\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-298138509966/rfc-pipeline-run-2022-06-25-12-17-45-068/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"criterion\":\"gini\",\"min_samples_split\":0.05,\"n_estimators\":50}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-298138509966/rfc-pipeline-run-2022-06-25-12-17-45-068/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"criterion\":\"gini\",\"min_samples_split\":0.05,\"n_estimators\":50},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rfc-pipeline-run-2022-06-25-12-17-45-068\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-298138509966/rfc-pipeline-run-2022-06-25-12-17-45-068/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--criterion\",\"gini\",\"--min_samples_split\",\"0.05\",\"--n_estimators\",\"50\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_CRITERION=gini\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_SAMPLES_SPLIT=0.05\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=50\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py --criterion gini --min_samples_split 0.05 --n_estimators 50\u001b[0m\n",
      "\n",
      "2022-06-25 12:22:06 Uploading - Uploading generated training model\u001b[34mTraining Accuracy: 0.9064\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 0.8667\u001b[0m\n",
      "\u001b[34mModel saved at /opt/ml/model/pipeline_model.joblib\u001b[0m\n",
      "\u001b[34m2022-06-25 12:22:03,624 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-06-25 12:22:44 Completed - Training job completed\n",
      "Training seconds: 80\n",
      "Billable seconds: 34\n",
      "Managed Spot Training savings: 57.5%\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "# Choose instance_type: https://aws.amazon.com/sagemaker/pricing/\n",
    "# Choose framework_version: https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    base_job_name=\"rfc-pipeline-run\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"train.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 50,\n",
    "        \"min_samples_split\": 0.05,\n",
    "        \"criterion\": \"gini\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    use_spot_instances=True,\n",
    "    max_wait=600,\n",
    "    max_run=600,\n",
    "    role=get_execution_role(),\n",
    ")\n",
    "\n",
    "# Launch Training job\n",
    "sklearn_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: rfc-pipeline-run-2022-06-25-12-17-45-068\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "training_job_name = sklearn_estimator.latest_training_job.name\n",
    "\n",
    "# Obtain the location of the model stored on S3 - Optional\n",
    "# You can directly copy the location of the artifact from S3 also!\n",
    "model_artifact = sm_client.describe_training_job(\n",
    "    TrainingJobName=training_job_name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(f\"Training job name: {training_job_name}\")\n",
    "print(f\"Model storage location: {model_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "- There are three types of parameters we can tune: https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    - IntegerParameter\n",
    "    - ContinuousParameter\n",
    "    - CategoricalParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Regex\n",
    "# import re\n",
    "# metric_string = \"Testing Accuracy: 0.8667\"\n",
    "# re.findall(r\"Testing Accuracy: ([0-9.]+).*$\", metric_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    \"n_estimators\": IntegerParameter(1, 20),\n",
    "    \"min_samples_split\": ContinuousParameter(0.01, 0.5),\n",
    "    \"criterion\": CategoricalParameter([\"gini\", \"entropy\", \"log_loss\"])\n",
    "}\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = HyperparameterTuner(\n",
    "    base_tuning_job_name=\"rfc-pipeline-tuner\",\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=\"Maximize\",\n",
    "    objective_metric_name=\"test-accuracy\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"train-accuracy\", \"Regex\": \"Training Accuracy: ([0-9.]+).*$\"},\n",
    "        {\"Name\": \"test-accuracy\", \"Regex\": \"Testing Accuracy: ([0-9.]+).*$\"}\n",
    "    ],\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "\n",
    "# Launch Optimizer job\n",
    "optimizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"entropy\"</td>\n",
       "      <td>0.373948</td>\n",
       "      <td>9.0</td>\n",
       "      <td>rfc-pipeline-tuner-220625-1230-004-8bf85030</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2022-06-25 12:37:26+00:00</td>\n",
       "      <td>2022-06-25 12:38:51+00:00</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"gini\"</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>10.0</td>\n",
       "      <td>rfc-pipeline-tuner-220625-1230-001-42f0c7e5</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>2022-06-25 12:32:39+00:00</td>\n",
       "      <td>2022-06-25 12:34:10+00:00</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"gini\"</td>\n",
       "      <td>0.075509</td>\n",
       "      <td>9.0</td>\n",
       "      <td>rfc-pipeline-tuner-220625-1230-010-8d60f27d</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>2022-06-25 12:48:36+00:00</td>\n",
       "      <td>2022-06-25 12:50:28+00:00</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"gini\"</td>\n",
       "      <td>0.203061</td>\n",
       "      <td>19.0</td>\n",
       "      <td>rfc-pipeline-tuner-220625-1230-009-01601b27</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>2022-06-25 12:50:03+00:00</td>\n",
       "      <td>2022-06-25 12:51:28+00:00</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"entropy\"</td>\n",
       "      <td>0.282199</td>\n",
       "      <td>16.0</td>\n",
       "      <td>rfc-pipeline-tuner-220625-1230-003-57b756d1</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>2022-06-25 12:36:55+00:00</td>\n",
       "      <td>2022-06-25 12:38:28+00:00</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  min_samples_split  n_estimators  \\\n",
       "6  \"entropy\"           0.373948           9.0   \n",
       "9     \"gini\"           0.084429          10.0   \n",
       "0     \"gini\"           0.075509           9.0   \n",
       "1     \"gini\"           0.203061          19.0   \n",
       "7  \"entropy\"           0.282199          16.0   \n",
       "\n",
       "                               TrainingJobName TrainingJobStatus  \\\n",
       "6  rfc-pipeline-tuner-220625-1230-004-8bf85030         Completed   \n",
       "9  rfc-pipeline-tuner-220625-1230-001-42f0c7e5         Completed   \n",
       "0  rfc-pipeline-tuner-220625-1230-010-8d60f27d         Completed   \n",
       "1  rfc-pipeline-tuner-220625-1230-009-01601b27         Completed   \n",
       "7  rfc-pipeline-tuner-220625-1230-003-57b756d1         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "6               0.9000 2022-06-25 12:37:26+00:00 2022-06-25 12:38:51+00:00   \n",
       "9               0.9000 2022-06-25 12:32:39+00:00 2022-06-25 12:34:10+00:00   \n",
       "0               0.8667 2022-06-25 12:48:36+00:00 2022-06-25 12:50:28+00:00   \n",
       "1               0.8333 2022-06-25 12:50:03+00:00 2022-06-25 12:51:28+00:00   \n",
       "7               0.7667 2022-06-25 12:36:55+00:00 2022-06-25 12:38:28+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "6                        85.0  \n",
       "9                        91.0  \n",
       "0                       112.0  \n",
       "1                        85.0  \n",
       "7                        93.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse tuning results\n",
    "results = optimizer.analytics().dataframe()\n",
    "\n",
    "results.sort_values(\"FinalObjectiveValue\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
