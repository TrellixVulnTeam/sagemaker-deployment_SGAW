{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas pandas-profiling scikit-learn sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    \"...\", # TODO: Paste the S3 path to your train.csv\n",
    "    nrows=100\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your test.csv\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(train_df)\n",
    "profile.to_file('profile_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Features and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns\n",
    "cat_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "cont_cols = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X(features) and y(response)\n",
    "X_train = train_df.drop(\"target\", axis=1)\n",
    "y_train = train_df[\"target\"]\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the categorical columns\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "# Scale the continuous columns\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Column transformer to apply transformations on both categorical and continuous columns\n",
    "ct = ColumnTransformer([\n",
    "    (\"One Hot Encoding\", ohe, cat_cols),\n",
    "    (\"Scaling\", sc, cont_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model\n",
    "- Random Forest documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to combine feature engineering and ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rfc_model = Pipeline([\n",
    "    (\"Data Transformations\", ct),\n",
    "    (\"Random Forest Model\", rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Pipeline Model locally\n",
    "- We run it locally to ensure there are no bugs in the code!\n",
    "- For this \"test\" purpose we can just run it on a smaller subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view tha Pipeline model as a diagram\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model locally on a smaller subset of data\n",
    "pipeline_rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy on training data\n",
    "train_accuracy = pipeline_rfc_model.score(X_train, y_train)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "# Check the accuracy on test data\n",
    "test_accuracy = pipeline_rfc_model.score(X_test, y_test)\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Pipeline Model on Sagemaker!\n",
    "- Since the model is free from bugs, we can train it on the full dataset.\n",
    "- Sagemaker training allows us to scale training to large datasets.\n",
    "- First we need to put all the code into a .py script\n",
    "- Sagemaker API documentation: https://sagemaker.readthedocs.io/en/stable/api/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_file_name = \"pipeline_model.joblib\"\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Inbuilt Arguments: https://github.com/aws/sagemaker-containers#id11\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    \n",
    "    # Custom Arguments\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--min_samples_split\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--criterion\", type=str, default=\"gini\")\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your train.csv\n",
    "    test_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your test.csv\n",
    "\n",
    "    # Define the columns\n",
    "    cat_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
    "    cont_cols = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
    "\n",
    "    # Split X(features) and y(response)\n",
    "    X_train = train_df.drop(\"target\", axis=1)\n",
    "    y_train = train_df[\"target\"]\n",
    "\n",
    "    X_test = test_df.drop(\"target\", axis=1)\n",
    "    y_test = test_df[\"target\"]\n",
    "\n",
    "    # One hot encode the categorical columns\n",
    "    ohe = OneHotEncoder(drop=\"first\")\n",
    "\n",
    "    # Scale the continuous columns\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Column transformer to apply transformations on both categorical and continuous columns\n",
    "    ct = ColumnTransformer([\n",
    "        (\"One Hot Encoding\", ohe, cat_cols),\n",
    "        (\"Scaling\", sc, cont_cols)\n",
    "    ])\n",
    "    \n",
    "    # Random Forest Model\n",
    "    rfc = RandomForestClassifier(n_estimators=args.n_estimators, \n",
    "                                 min_samples_split=args.min_samples_split,\n",
    "                                 criterion=args.criterion)\n",
    "\n",
    "    # Sklearn pipeline\n",
    "    pipeline_rfc_model = Pipeline([\n",
    "        (\"Data Transformations\", ct),\n",
    "        (\"Random Forest Model\", rfc)\n",
    "    ])\n",
    "\n",
    "    # Fit the model locally on a smaller subset of data\n",
    "    pipeline_rfc_model.fit(X_train, y_train)\n",
    "\n",
    "    # Check the accuracy on training data\n",
    "    train_accuracy = pipeline_rfc_model.score(X_train, y_train)\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Check the accuracy on test data\n",
    "    test_accuracy = pipeline_rfc_model.score(X_test, y_test)\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model_save_path = os.path.join(args.model_dir, model_file_name)\n",
    "    joblib.dump(pipeline_rfc_model, model_save_path)\n",
    "    print(f\"Model saved at {model_save_path}\")\n",
    "\n",
    "# Run the main function when the script runs\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "scikit-learn\n",
    "fsspec\n",
    "s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "# Choose instance_type: https://aws.amazon.com/sagemaker/pricing/\n",
    "# Choose framework_version: https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    base_job_name=\"rfc-pipeline-run\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"train.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 50,\n",
    "        \"min_samples_split\": 0.05,\n",
    "        \"criterion\": \"gini\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    use_spot_instances=True,\n",
    "    max_wait=600,\n",
    "    max_run=600,\n",
    "    role=get_execution_role(),\n",
    ")\n",
    "\n",
    "# Launch Training job\n",
    "sklearn_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the training job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "training_job_name = sklearn_estimator.latest_training_job.name\n",
    "\n",
    "# Obtain the location of the model stored on S3 - Optional\n",
    "# You can directly copy the location of the artifact from S3 also!\n",
    "model_artifact = sm_client.describe_training_job(\n",
    "    TrainingJobName=training_job_name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(f\"Training job name: {training_job_name}\")\n",
    "print(f\"Model storage location: {model_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "- There are three types of parameters we can tune: https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "    - IntegerParameter\n",
    "    - ContinuousParameter\n",
    "    - CategoricalParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Regex\n",
    "import re\n",
    "metric_string = \"Testing Accuracy: 0.8667\"\n",
    "re.findall(r\"Testing Accuracy: ([0-9.]+).*$\", metric_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "\n",
    "# Define exploration boundaries\n",
    "hyperparameter_ranges = {\n",
    "    \"n_estimators\": IntegerParameter(1, 20),\n",
    "    \"min_samples_split\": ContinuousParameter(0.01, 0.5),\n",
    "    \"criterion\": CategoricalParameter([\"gini\", \"entropy\"])\n",
    "}\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = HyperparameterTuner(\n",
    "    base_tuning_job_name=\"rfc-pipeline-tuner\",\n",
    "    estimator=sklearn_estimator,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    objective_type=\"Maximize\",\n",
    "    objective_metric_name=\"test-accuracy\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"train-accuracy\", \"Regex\": \"Training Accuracy: ([0-9.]+).*$\"},\n",
    "        {\"Name\": \"test-accuracy\", \"Regex\": \"Testing Accuracy: ([0-9.]+).*$\"}\n",
    "    ],\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "\n",
    "# Launch Optimizer job\n",
    "optimizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse tuning results\n",
    "results = optimizer.analytics().dataframe()\n",
    "\n",
    "results.sort_values(\"FinalObjectiveValue\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
