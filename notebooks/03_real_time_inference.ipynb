{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the inference script\n",
    "- Since the model has been trained with good accuracy we can deploy it.\n",
    "- First we need to write the 4 functions for model inference in a .py script\n",
    "- Sagemaker API documentation: https://sagemaker.readthedocs.io/en/stable/api/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile serve.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Model\n",
    "def model_fn(model_dir):\n",
    "    model_file_name = \"pipeline_model.joblib\"\n",
    "    pipeline_model = joblib.load(os.path.join(model_dir, model_file_name))\n",
    "    \n",
    "    return pipeline_model\n",
    "\n",
    "# Load the input data\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"An input_fn that loads a pickled numpy array\"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        data = json.loads(request_body)\n",
    "        input_object = pd.DataFrame(data)\n",
    "        \n",
    "        return input_object\n",
    "    else:\n",
    "        raise ValueError(\"Only application/json content type supported!\")\n",
    "\n",
    "def predict_fn(input_object, pipeline_model):\n",
    "    prediction = pipeline_model.predict(input_object).tolist()\n",
    "    pred_prob = pipeline_model.predict_proba(input_object).tolist()\n",
    "    \n",
    "    prediction_object = {\n",
    "        \"predictions\": prediction, \n",
    "        \"pred_prob\": pred_prob\n",
    "    }\n",
    "    \n",
    "    return prediction_object\n",
    "\n",
    "def output_fn(prediction_object, request_content_type):\n",
    "    return_object = json.dumps(prediction_object)\n",
    "    \n",
    "    return return_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Endpoint Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "training_job_name = \"knn-pipeline-tuner-220611-0916-006-77833ec6\"\n",
    "model_artifact = f\"s3://sagemaker-us-east-1-298138509966/{training_job_name}/output/model.tar.gz\"\n",
    "endpoint_name = \"heart-disease-knn-pipeline-model\"\n",
    "\n",
    "model = SKLearnModel(\n",
    "    name=endpoint_name,\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=model_artifact,\n",
    "    role=get_execution_role(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy!\n",
    "predictor = model.deploy(instance_type=\"ml.t3.medium\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(\"Endpoint name:\")\n",
    "print(f\"{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "import json\n",
    "test_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/test.csv\")\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_dict(orient=\"records\")\n",
    "\n",
    "# Convert the list of dictionaries to a json string\n",
    "X_pred = json.dumps(X_pred)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "import json\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                      Body=X_pred, \n",
    "                                      ContentType=\"application/json\", \n",
    "                                      Accept=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response from the endpoint\n",
    "response_body = response['Body']\n",
    "response_str = response_body.read().decode('utf-8')\n",
    "response_dict = json.loads(response_str)\n",
    "\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def cleanup(endpoint_name):\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # Get the model name from endpoint_name\n",
    "    response = sm_client.describe_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "\n",
    "    # Delete the endpoint\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "    # Delete the endpoint config\n",
    "    endpoint_config_name = response['EndpointConfigName']\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)                        \n",
    "\n",
    "    # Delete the model\n",
    "    model_name = response['ProductionVariants'][0]['ModelName']\n",
    "    sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Model Endpoint\n",
    "- You can deploy more than one model to same physical machine to save on costs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-model deployment\n",
    "from sagemaker import Session\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "mme_name = \"heart-disease-models\"\n",
    "mme_model_data_prefix = f\"s3://sagemaker-us-east-1-298138509966/{mme_name}\"\n",
    "\n",
    "# Define the base model\n",
    "base_model = SKLearnModel(\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=None,\n",
    "    role=get_execution_role(),\n",
    "    sagemaker_session = Session()\n",
    ")\n",
    "\n",
    "# Define the multi-model\n",
    "mme = MultiDataModel(\n",
    "    name = mme_name,\n",
    "    model_data_prefix = mme_model_data_prefix,\n",
    "    model = base_model,\n",
    "    sagemaker_session = Session()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "# Deploy the empty multi-model!\n",
    "predictor = mme.deploy(instance_type=\"ml.t2.large\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-298138509966/heart-disease-models/knn-pipeline-run-2022-06-11-03-03-10-696_2.tar.gz'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the first model to the multi-model\n",
    "training_job_name = \"knn-pipeline-tuner-220611-0916-006-77833ec6\"\n",
    "model_artifact = f\"s3://sagemaker-us-east-1-298138509966/{training_job_name}/output/model.tar.gz\"\n",
    "model_name = f\"{model_artifact.split('/')[-3]}_1.tar.gz\"\n",
    "\n",
    "mme.add_model(model_data_source=model_artifact, model_data_path=model_name)\n",
    "\n",
    "# Add the second model to the multi-model\n",
    "training_job_name = \"knn-pipeline-tuner-220611-0916-006-77833ec6\"\n",
    "model_artifact = f\"s3://sagemaker-us-east-1-298138509966/{training_job_name}/output/model.tar.gz\"\n",
    "model_name = f\"{model_artifact.split('/')[-3]}_2.tar.gz\"\n",
    "\n",
    "mme.add_model(model_data_source=model_artifact, model_data_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/knn-pipeline-run-2022-06-11-03-03-10-696_1.tar.gz',\n",
       " '/knn-pipeline-run-2022-06-11-03-03-10-696_2.tar.gz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all the models have been deployed\n",
    "list(mme.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the models\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"age\": 45.0, \"sex\": 0.0, \"cp\": 2.0, \"trestbps\": 112.0, \"chol\": 160.0, \"fbs\": 0.0, \"restecg\": 0.0, \"thalach\": 138.0, \"exang\": 0.0, \"oldpeak\": 0.0, \"slope\": 2.0, \"ca\": 0.0, \"thal\": 3.0}, {\"age\": 52.0, \"sex\": 1.0, \"cp\": 4.0, \"trestbps\": 112.0, \"chol\": 230.0, \"fbs\": 0.0, \"restecg\": 0.0, \"thalach\": 160.0, \"exang\": 0.0, \"oldpeak\": 0.0, \"slope\": 1.0, \"ca\": 1.0, \"thal\": 3.0}]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "import json\n",
    "test_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/test.csv\")\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_dict(orient=\"records\")\n",
    "\n",
    "# Convert the list of dictionaries to a json string\n",
    "X_pred = json.dumps(X_pred)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/knn-pipeline-run-2022-06-11-03-03-10-696_1.tar.gz\n",
      "{'predictions': [0, 1], 'pred_prob': [[1.0, 0.0], [0.4, 0.6]]}\n",
      "/knn-pipeline-run-2022-06-11-03-03-10-696_2.tar.gz\n",
      "{'predictions': [0, 1], 'pred_prob': [[1.0, 0.0], [0.4, 0.6]]}\n"
     ]
    }
   ],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "import json\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = mme_name\n",
    "\n",
    "# Predictions from each model\n",
    "for model_name in mme.list_models():\n",
    "    response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                          TargetModel=model_name,\n",
    "                                          Body=X_pred, \n",
    "                                          ContentType=\"application/json\", \n",
    "                                          Accept=\"application/json\")\n",
    "\n",
    "    # Decode the response from the endpoint\n",
    "    response_body = response['Body']\n",
    "    response_str = response_body.read().decode('utf-8')\n",
    "    response_dict = json.loads(response_str)\n",
    "    \n",
    "    print(model_name)\n",
    "    print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f4d731a1-7bdf-4231-a7f9-0a85bc714ed1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f4d731a1-7bdf-4231-a7f9-0a85bc714ed1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sat, 11 Jun 2022 03:35:27 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "training_job_name = \"knn-pipeline-tuner-220611-0916-006-77833ec6\"\n",
    "model_artifact = f\"s3://sagemaker-us-east-1-298138509966/{training_job_name}/output/model.tar.gz\"\n",
    "endpoint_name = \"heart-disease-knn-pipeline-model\"\n",
    "\n",
    "model = SKLearnModel(\n",
    "    name=endpoint_name,\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=model_artifact,\n",
    "    role=get_execution_role(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW! Create a config for serverless inference\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "serverless_config = ServerlessInferenceConfig(memory_size_in_mb=1024, max_concurrency=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------!"
     ]
    }
   ],
   "source": [
    "# NEW! Deploy!\n",
    "predictor = model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:\n",
      "heart-disease-knn-pipeline-model-2022-06-11-09-52-24-858\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(\"Endpoint name:\")\n",
    "print(f\"{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"age\": 45.0, \"sex\": 0.0, \"cp\": 2.0, \"trestbps\": 112.0, \"chol\": 160.0, \"fbs\": 0.0, \"restecg\": 0.0, \"thalach\": 138.0, \"exang\": 0.0, \"oldpeak\": 0.0, \"slope\": 2.0, \"ca\": 0.0, \"thal\": 3.0}, {\"age\": 52.0, \"sex\": 1.0, \"cp\": 4.0, \"trestbps\": 112.0, \"chol\": 230.0, \"fbs\": 0.0, \"restecg\": 0.0, \"thalach\": 160.0, \"exang\": 0.0, \"oldpeak\": 0.0, \"slope\": 1.0, \"ca\": 1.0, \"thal\": 3.0}]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "import json\n",
    "test_df = pd.read_csv(\"s3://sagemaker-us-east-1-298138509966/sagemaker/heart_disease/test.csv\")\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_dict(orient=\"records\")\n",
    "\n",
    "# Convert the list of dictionaries to a json string\n",
    "X_pred = json.dumps(X_pred)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "import json\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                      Body=X_pred, \n",
    "                                      ContentType=\"application/json\", \n",
    "                                      Accept=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [0, 1], 'pred_prob': [[1.0, 0.0], [0.3333333333333333, 0.6666666666666666]]}\n"
     ]
    }
   ],
   "source": [
    "# Decode the response from the endpoint\n",
    "response_body = response['Body']\n",
    "response_str = response_body.read().decode('utf-8')\n",
    "response_dict = json.loads(response_str)\n",
    "\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
