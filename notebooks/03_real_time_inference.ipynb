{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U pandas pandas-profiling scikit-learn sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the inference script\n",
    "- Since the model has been trained with good accuracy we can deploy it.\n",
    "- First we need to write the 4 functions for model inference in a .py script\n",
    "- Sagemaker API documentation: https://sagemaker.readthedocs.io/en/stable/api/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile serve.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load and return the model\"\"\"\n",
    "    model_file_name = \"pipeline_model.joblib\"\n",
    "    pipeline_model = joblib.load(os.path.join(model_dir, model_file_name))\n",
    "    \n",
    "    return pipeline_model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Process the input json data and return the processed data.\n",
    "    You can also add any input data pre-processing in this function\n",
    "    \"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        input_object = pd.read_json(request_body, lines=True)\n",
    "        \n",
    "        return input_object\n",
    "    else:\n",
    "        raise ValueError(\"Only application/json content type supported!\")\n",
    "\n",
    "def predict_fn(input_object, pipeline_model):\n",
    "    \"\"\"Make predictions on processed input data\"\"\"\n",
    "    predictions = pipeline_model.predict(input_object)\n",
    "    pred_probs = pipeline_model.predict_proba(input_object)\n",
    "    \n",
    "    prediction_object = pd.DataFrame(\n",
    "        {\n",
    "            \"prediction\": predictions.tolist(),\n",
    "            \"pred_prob_class0\": pred_probs[:, 0].tolist(),\n",
    "            \"pred_prob_class1\": pred_probs[:, 1].tolist()\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return prediction_object\n",
    "\n",
    "def output_fn(prediction_object, request_content_type):\n",
    "    \"\"\"Post process the predictions and return as json\"\"\"\n",
    "    return_object = prediction_object.to_json(orient=\"records\", lines=True)\n",
    "    \n",
    "    return return_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "pandas\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Endpoint Deployment\n",
    "- Supported machines and cost: https://aws.amazon.com/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "session = Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "training_job_name = \"...\" # TODO: Update with best TrainingJobName from hyperparameter tuning\n",
    "model_artifact = f\"s3://{bucket}/{training_job_name}/output/model.tar.gz\"\n",
    "endpoint_name = \"heart-disease-rfc-pipeline-real-time\"\n",
    "\n",
    "model = SKLearnModel(\n",
    "    name=endpoint_name,\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=model_artifact,\n",
    "    role=get_execution_role(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy!\n",
    "predictor = model.deploy(instance_type=\"ml.t2.medium\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(\"Endpoint name:\")\n",
    "print(f\"{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your test.csv\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_json(orient=\"records\", lines=True)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                      Body=X_pred, \n",
    "                                      ContentType=\"application/json\", \n",
    "                                      Accept=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response from the endpoint\n",
    "response_body = response['Body']\n",
    "response_str = response_body.read().decode('utf-8')\n",
    "response_df = pd.read_json(response_str, lines=True)\n",
    "\n",
    "response_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def cleanup(endpoint_name):\n",
    "    sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    # Get the model name from endpoint_name\n",
    "    response = sm_client.describe_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "\n",
    "    # Delete the endpoint\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "    # Delete the endpoint config\n",
    "    endpoint_config_name = response['EndpointConfigName']\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)                        \n",
    "\n",
    "    # Delete the model\n",
    "    model_name = response['ProductionVariants'][0]['ModelName']\n",
    "    sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Model Endpoint\n",
    "- You can deploy more than one model to same physical machine to save on costs!\n",
    "- Supported machines and cost: https://aws.amazon.com/sagemaker/pricing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-model deployment\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from sagemaker import Session, get_execution_role\n",
    "\n",
    "session = Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "mme_name = \"heart-disease-models\"\n",
    "mme_model_data_prefix = f\"s3://{bucket}/{mme_name}\"\n",
    "\n",
    "# Define the base model\n",
    "base_model = SKLearnModel(\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=None,\n",
    "    role=get_execution_role(),\n",
    "    sagemaker_session = session\n",
    ")\n",
    "\n",
    "# Define the multi-model\n",
    "mme = MultiDataModel(\n",
    "    name = mme_name,\n",
    "    model_data_prefix = mme_model_data_prefix,\n",
    "    model = base_model,\n",
    "    sagemaker_session = session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the empty multi-model!\n",
    "predictor = mme.deploy(instance_type=\"ml.t2.large\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first model to the multi-model\n",
    "training_job_name = \"...\" # TODO: Update with best TrainingJobName from hyperparameter tuning\n",
    "model_artifact = f\"s3://{bucket}/{training_job_name}/output/model.tar.gz\"\n",
    "model_name = f\"{model_artifact.split('/')[-3]}_1.tar.gz\"\n",
    "\n",
    "mme.add_model(model_data_source=model_artifact, model_data_path=model_name)\n",
    "\n",
    "# Add the second model to the multi-model\n",
    "training_job_name = \"...\" # TODO: Update with best TrainingJobName from hyperparameter tuning\n",
    "model_artifact = f\"s3://{bucket}/{training_job_name}/output/model.tar.gz\"\n",
    "model_name = f\"{model_artifact.split('/')[-3]}_2.tar.gz\"\n",
    "\n",
    "mme.add_model(model_data_source=model_artifact, model_data_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all the models have been deployed\n",
    "list(mme.list_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the models\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your test.csv\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_json(orient=\"records\", lines=True)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "endpoint_name = mme_name\n",
    "\n",
    "# Predictions from each model\n",
    "for model_name in mme.list_models():\n",
    "    response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                          TargetModel=model_name,\n",
    "                                          Body=X_pred, \n",
    "                                          ContentType=\"application/json\", \n",
    "                                          Accept=\"application/json\")\n",
    "\n",
    "    # Decode the response from the endpoint\n",
    "    response_body = response['Body']\n",
    "    response_str = response_body.read().decode('utf-8')\n",
    "    response_df = pd.read_json(response_str, lines=True)\n",
    "    \n",
    "    print(model_name)\n",
    "    print(response_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serverless\n",
    "- Most cost effective option for real time inference\n",
    "- Only runs when there is traffic so small delay in latency of first prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the deployment\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import Session, get_execution_role\n",
    "\n",
    "session = Session()\n",
    "bucket = session.default_bucket()\n",
    "\n",
    "training_job_name = \"...\" # TODO: Update with best TrainingJobName from hyperparameter tuning\n",
    "model_artifact = f\"s3://{bucket}/{training_job_name}/output/model.tar.gz\"\n",
    "endpoint_name = \"heart-disease-rfc-pipeline-real-time\"\n",
    "\n",
    "model = SKLearnModel(\n",
    "    name=endpoint_name,\n",
    "    framework_version=\"1.0-1\",\n",
    "    entry_point=\"serve.py\",\n",
    "    dependencies=[\"requirements.txt\"],\n",
    "    model_data=model_artifact,\n",
    "    role=get_execution_role(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW! Create a config for serverless inference\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "serverless_config = ServerlessInferenceConfig(memory_size_in_mb=1024, max_concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW! Deploy!\n",
    "predictor = model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(\"Endpoint name:\")\n",
    "print(f\"{endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the model\n",
    "- boto3 documentation: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data that we want to make predictions on\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"...\") # TODO: Paste the S3 path to your test.csv\n",
    "\n",
    "X_test = test_df.drop(\"target\", axis=1)\n",
    "y_test = test_df[\"target\"]\n",
    "\n",
    "# Get two rows to make predictions on\n",
    "X_pred = X_test.head(2).to_json(orient=\"records\", lines=True)\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit to the endpoint\n",
    "import boto3\n",
    "\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                      Body=X_pred, \n",
    "                                      ContentType=\"application/json\", \n",
    "                                      Accept=\"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response from the endpoint\n",
    "response_body = response['Body']\n",
    "response_str = response_body.read().decode('utf-8')\n",
    "response_df = pd.read_json(response_str, lines=True)\n",
    "\n",
    "response_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "- Delete the endpoint\n",
    "- Delete the endpoint config\n",
    "- Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleanup\n",
    "cleanup(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
